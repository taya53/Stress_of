# -*- coding: utf-8 -*-
"""Classification project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16IbTZlXkOqzAQUZf6aRvWstGmDeylsz6

**Importing the most important packages**
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier

"""Importing **data**"""

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv("/content/drive/MyDrive/MMH_15p.csv")

data

#I deleted fatiguestate because it's already in the data as fatiguestate1 and Unnamed 
data = data.drop(labels=None, axis=0, index=None, columns = ['Unnamed: 0','fatiguestate'], level=None, inplace=False, errors='raise')

#convert subject to number like P13 to 13
subjectt = {'P1':1,'P2':2,'P3':3,'P4':4,'P5':5,'P6':6,'P7':7,'P8':8,'P9':9,'P10':10,'P11':11,'P12':12,'P13':13,'P14':14,'P15':15}
data.subject = [subjectt[item] for item in data.subject]

data['task'].unique()

#u can see from the last cell the variance of task is null so we will delete it
data = data.drop( columns = 'task')

"""Splitting data to **training** and **testing**"""

X = data.drop('fatiguestate1', axis=1)
y = data['fatiguestate1']

X.shape

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

"""Now let's do the **modelling** part"""

model = ExtraTreesClassifier(n_estimators=100, random_state=0)

"""Training the model on **training** set"""

model.fit(X_train, y_train)

"""After training we **predict** the testing set with our trained model"""

y_pred = model.predict(X_test)

"""Let's see **the** **accuracy** of our model on testing set"Unseen data"

"""

accuracy_score(y_pred, y_test)

"""**Let's try cross validation**"""

scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')

scores
#94 is an unexpected score !!

"""plot of **Confusion Matrix** on **testing** set"""

plot_confusion_matrix(model, X_test, y_test)
plt.show()

"""plot of **Confusion Matrix** on **training** set"""

plot_confusion_matrix(model, X_train, y_train)
plt.show()

"""**References**

**Working with Logistic regression**
"""

model = LogisticRegression(random_state=0)

model.fit(X_train,y_train)

y_pred = model.predict(X_test)

accuracy_score(y_pred, y_test)

scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')

scores

plot_confusion_matrix(model, X_test, y_test)
plt.show()

"""**The naive bayes**"""

model = GaussianNB()

model.fit(X_train,y_train)

y_pred = model.predict(X_test)

accuracy_score(y_pred, y_test)

scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')

scores

plot_confusion_matrix(model, X_test, y_test)
plt.show()

"""**KNeighbors**"""

model = KNeighborsClassifier(n_neighbors=2)

model.fit(X_train,y_train)

y_pred = model.predict(X_test)

accuracy_score(y_pred, y_test)

scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')

scores

plot_confusion_matrix(model, X_test, y_test)
plt.show()